{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Goal\n",
    "The goal in this competition is to take an image of a handwritten single digit, and determine what that digit is.\n",
    "For every in the test set, you should predict the correct label.\n",
    "# Metric\n",
    "This competition is evaluated on the categorization accuracy of your predictions (the percentage of images you get correct).\n",
    "\n",
    "# Submission File Format\n",
    "The file should contain a header and have the following format:\n",
    "\n",
    "ImageId,Label\n",
    "* 1,0\n",
    "* 2,0\n",
    "* 3,0\n",
    "* etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这个程序中，我们使用已经被卷积核锐化过的数据集结合CNN进行预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "import warnings\n",
    "# filter warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先用pandas读入csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv('convolution_data.csv') # 导入卷积核锐化后的训练集进行训练\n",
    "Y = df.iloc[:, 0].values  # 标签数据\n",
    "X = df.iloc[:, 1:].values  # 特征数据\n",
    "Y_test = df.iloc[:, 0].values   # 标签数据\n",
    "X_test = df.iloc[:, 1:].values  # 特征数据\n",
    "np.save(\"X.npy\", X)\n",
    "np.save(\"Y.npy\", Y)\n",
    "X_train = np.load('X.npy')\n",
    "Y_train = np.load('Y.npy')\n",
    "\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15, random_state=42)\n",
    "\n",
    "print(\"数据形状:\", X_train.shape) \n",
    "print(\"数据形状:\", Y_train.shape) \n",
    "print(\"数据形状:\", X_test.shape) \n",
    "print(\"数据形状:\", Y_test.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data set\n",
    "img_size = 28\n",
    "dataX = np.load('X.npy') # 查看数据形状\n",
    "print(\"数据形状:\", dataX.shape) # 打印前五行数据 \n",
    "print(dataX[:10])\n",
    "dataY = np.load('Y.npy') # 查看数据形状\n",
    "print(\"数据形状:\", dataY.shape) # 打印前五行数据\n",
    "\n",
    "print(dataY[:10])\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(dataX[290].reshape(img_size, img_size))\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(dataX[950].reshape(img_size, img_size))\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(dataX[1560].reshape(img_size, img_size))\n",
    "plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看卷积核锐化后的图像，有一定效果，并且保留了图形的绝大部分轮廓"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 为手势零的图像创建标签数组，其值为0，为一手势的图像创建标签数组，其值为1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = Y_test.reshape(-1, 1)\n",
    "Y_train = Y_train.reshape(-1, 1)\n",
    "print(\"Y_test shape: \", Y_test.shape)\n",
    "print(\"Y_train shape: \", Y_train.shape)\n",
    "print(\"X_shape: \" , X.shape)\n",
    "print(\"Y_shape: \" , Y.shape)\n",
    "print(\"X_test shape: \" , X_test.shape)\n",
    "print(\"Y_test shape: \" , Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then lets create x_train, y_train, x_test, y_test arrays\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15, random_state=42)\n",
    "\n",
    "number_of_train = X_train.shape[0]\n",
    "number_of_test = X_test.shape[0]\n",
    "print(\"X_train number: \" , number_of_train)\n",
    "print(\"X_test number: \" , number_of_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 现在我们有3维的输入数组（X），为了将其作为感知机模型的输入，我们需要将其展平为2维\n",
    "* 我们的标签数组（Y）已经是展平的（2D），所以我们保持不变。\n",
    "* 将X数组（图像数组）展平。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_flatten = X_train.reshape(number_of_train,X_train.shape[1]*X_train.shape[2])\n",
    "# X_test_flatten = X_test .reshape(number_of_test,X_test.shape[1]*X_test.shape[2])\n",
    "# print(\"X train flatten\",X_train_flatten.shape)\n",
    "# print(\"X test flatten\",X_test_flatten.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 为方便后续矩阵乘法的计算，对样本矩阵进行转置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = Y_train.T\n",
    "y_test = Y_test.T\n",
    "print(\"x train: \",X_train.shape)\n",
    "print(\"x test: \",X_test.shape)\n",
    "print(\"y train: \",y_train.shape)\n",
    "print(\"y test: \",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- <a id=\"10\"></a> <br>\n",
    "# 深度神经网络(DNN)\n",
    "* 2-layer 感知机: \n",
    "    * 神经网络结构： 包括输入层、一个或多个隐藏层以及输出层。\n",
    "    * 激活函数： 激活函数提供了非线性变换，使模型具备拟合复杂数据的能力。tanh激活函数比sigmoid更适合用于隐藏单元，因为它的输出均值更接近于零，从而更好地中心化数据以供下一层使用。\n",
    "\n",
    "<a href=\"http://ibb.co/eF315x\"><img src=\"http://preview.ibb.co/dajVyH/9.jpg\" alt=\"9\" border=\"0\"></a>\n",
    "\n",
    "   \n",
    "    \n",
    "     -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 创建卷积神经网络模型\n",
    "Size_of_Core = 5\n",
    "\n",
    "model = Sequential(\n",
    "    [\n",
    "        # 第一层卷积层：32个5x5的卷积核，激活函数ReLU，填充方式为SAME\n",
    "        Conv2D(\n",
    "            32,\n",
    "            (Size_of_Core, Size_of_Core),\n",
    "            activation=\"relu\",\n",
    "            input_shape=(28, 28, 1),\n",
    "            padding=\"same\",\n",
    "        ),\n",
    "        # 第一层池化层：2x2最大池化\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.25),  # 添加Dropout层，防止过拟合\n",
    "        # 第二层卷积层：64个5x5的卷积核，激活函数ReLU，填充方式为SAME\n",
    "        Conv2D(64, (Size_of_Core, Size_of_Core), activation=\"relu\", padding=\"same\"),\n",
    "        # 第二层池化层：2x2最大池化\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.25),\n",
    "        # 第三层卷积层：128个5x5的卷积核，激活函数ReLU，填充方式为SAME\n",
    "        Conv2D(128, (Size_of_Core, Size_of_Core), activation=\"relu\", padding=\"same\"),\n",
    "        # 第三层池化层：2x2最大池化\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.25),\n",
    "        # 展平层，将二维图像数据展平为一维\n",
    "        Flatten(),\n",
    "        # 全连接层：128个神经元，激活函数ReLU\n",
    "        Dense(128, activation=\"relu\"),\n",
    "        Dropout(0.5),  # 再次添加Dropout层\n",
    "        # 输出层：10个神经元（对应10个分类），激活函数Softmax\n",
    "        Dense(10, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 数据增强\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,  # 随机旋转范围\n",
    "    width_shift_range=0.1,  # 水平移动\n",
    "    height_shift_range=0.1,  # 垂直移动\n",
    "    shear_range=0.1,  # 剪切变换程度\n",
    "    zoom_range=0.1,  # 放大/缩小  \n",
    "    horizontal_flip=False,  # 水平翻转\n",
    "    fill_mode=\"nearest\",  # 填充模式\n",
    ")\n",
    "\n",
    "# 打印模型摘要，检查各层的输出形状\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# 假设你已经有了自己的训练数据 X_train 和 y_train\n",
    "# 处理现有的训练数据 X_train（假设它是二维的）\n",
    "X_train = (\n",
    "    X_train.reshape(X_train.shape[0], 28, 28, 1).astype(\"float32\") / 255.0\n",
    ")  # 调整为 (num_samples, 28, 28, 1)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(\n",
    "    optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# 使用数据增强进行训练\n",
    "datagen.fit(X_train)\n",
    "model.fit(\n",
    "    datagen.flow(X_train, y_train, batch_size=32),\n",
    "    epochs=20,\n",
    "    validation_data=(X_test, y_test),  # 用 MNIST 测试集验证\n",
    ")\n",
    "\n",
    "# 在测试数据上进行评估\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "相比于之前手写的简单的锐化函数，用卷积核锐化的准确度又有了明显提升。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"test.csv\")\n",
    "test_X = test_df.iloc[:, :].values  \n",
    "print(\"数据形状:\", test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X_2D=np.array([test_X[i].reshape(28,28) for i in range(28000)])\n",
    "test_X_2D.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面使用相同的卷积核锐化方式对预测图片集进行锐化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharpen_kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]]) # 这样的卷积核可以强化图像的中心特征\n",
    "\n",
    "# 假设 dataX_2D 是包含彩色图像的数组，形状为 (28000, 高, 宽, 3)\n",
    "test_X_2D_convolution = [[] for _ in range(28000)]\n",
    "\n",
    "for i in range(28000):\n",
    "    # 确保每张图像是 uint8 类型，且是彩色图像\n",
    "    image = test_X_2D[i].astype(np.uint8)\n",
    "\n",
    "    # 对彩色图像应用锐化滤波\n",
    "    test_X_2D_convolution[i] = cv2.filter2D(image, -1, sharpen_kernel)\n",
    "test_X_2D_convolution=np.array(test_X_2D_convolution)\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(test_X_2D_convolution[3].reshape(img_size, img_size))\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(test_X_2D_convolution[83].reshape(img_size, img_size))\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(test_X_2D_convolution[1500].reshape(img_size, img_size))\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_number=test_X_2D_convolution.shape[0]\n",
    "test_X_2D_convolution = (test_X_2D_convolution.reshape(test_number, 28, 28, 1).astype(\"float32\") / 255.0)\n",
    "print(test_X_2D_convolution.shape)\n",
    "print(test_X_2D_convolution[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设 prediction 是模型预测的结果\n",
    "prediction = model.predict(test_X_2D_convolution)\n",
    "\n",
    "# 获取最大值的索引作为预测的类别\n",
    "predicted_class = np.argmax(prediction, axis=-1)\n",
    "\n",
    "# 将预测结果转换为 DataFrame\n",
    "output_df = pd.DataFrame(predicted_class, columns=[\"Label\"])\n",
    "\n",
    "# 添加 ImageId 列，假设它是从 1 开始的\n",
    "output_df[\"ImageId\"] = output_df.index + 1\n",
    "\n",
    "# 重新排列列顺序，以确保 'ImageId' 在前\n",
    "output_df = output_df[[\"ImageId\", \"Label\"]]\n",
    "\n",
    "# 将 DataFrame 写入 CSV 文件\n",
    "output_df.to_csv(\"output_convolution.csv\", index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
