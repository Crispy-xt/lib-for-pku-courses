{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Goal\n",
    "The goal in this competition is to take an image of a handwritten single digit, and determine what that digit is.\n",
    "For every in the test set, you should predict the correct label.\n",
    "# Metric\n",
    "This competition is evaluated on the categorization accuracy of your predictions (the percentage of images you get correct).\n",
    "\n",
    "# Submission File Format\n",
    "The file should contain a header and have the following format:\n",
    "\n",
    "ImageId,Label\n",
    "* 1,0\n",
    "* 2,0\n",
    "* 3,0\n",
    "* etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"数据集\"></a> <br>\n",
    "# 数据集概览\n",
    "* 在本教程中，我们将使用“手语数字数据集”。\n",
    "* 该数据集中包含2062张手语数字图片。\n",
    "* 数字范围是从0到9。因此共有10个不同的手势。\n",
    "* 为了简化起见，我们仅使用手势0和1。\n",
    "* 准备我们的X和Y数组。X是图像数组（手势零和一手势），Y是标签数组（0和1）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "import warnings\n",
    "# filter warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据形状: (35700, 784)\n",
      "数据形状: (35700,)\n",
      "数据形状: (6300, 784)\n",
      "数据形状: (6300,)\n"
     ]
    }
   ],
   "source": [
    "# 先用pandas读入csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv('train.csv')\n",
    "Y = df.iloc[:, 0].values   # 标签数据\n",
    "X = df.iloc[:, 1:].values  # 特征数据\n",
    "np.save(\"X.npy\", X)\n",
    "np.save(\"Y.npy\", Y)\n",
    "X_train = np.load('X.npy')\n",
    "Y_train = np.load('Y.npy')\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15, random_state=42)\n",
    "\n",
    "print(\"数据形状:\", X_train.shape) \n",
    "print(\"数据形状:\", Y_train.shape) \n",
    "print(\"数据形状:\", X_test.shape) \n",
    "print(\"数据形状:\", Y_test.shape) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据形状: (42000, 784)\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "数据形状: (42000,)\n",
      "[1 0 1 4 0 0 7 3 5 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load data set\n",
    "img_size = 28\n",
    "dataX = np.load('X.npy') # 查看数据形状\n",
    "print(\"数据形状:\", dataX.shape) # 打印前五行数据 \n",
    "print(dataX[:10])\n",
    "dataY = np.load('Y.npy') # 查看数据形状\n",
    "print(\"数据形状:\", dataY.shape) # 打印前五行数据\n",
    "\n",
    "print(dataY[:10])\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(dataX[260].reshape(img_size, img_size))\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(dataX[900].reshape(img_size, img_size))\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(dataX[1500].reshape(img_size, img_size))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 为手势零的图像创建标签数组，其值为0，为一手势的图像创建标签数组，其值为1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_test shape:  (6300, 1)\n",
      "Y_train shape:  (35700, 1)\n",
      "X_shape:  (42000, 784)\n",
      "Y_shape:  (42000,)\n",
      "X_test shape:  (6300, 784)\n",
      "Y_test shape:  (6300, 1)\n"
     ]
    }
   ],
   "source": [
    "Y_test = Y_test.reshape(-1, 1)\n",
    "Y_train = Y_train.reshape(-1, 1)\n",
    "print(\"Y_test shape: \", Y_test.shape)\n",
    "print(\"Y_train shape: \", Y_train.shape)\n",
    "print(\"X_shape: \" , X.shape)\n",
    "print(\"Y_shape: \" , Y.shape)\n",
    "print(\"X_test shape: \" , X_test.shape)\n",
    "print(\"Y_test shape: \" , Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_size = 5000 # 选择较小的样本数量\n",
    "# sample_size = min(5000, X_test.shape[0])\n",
    "# indices = np.random.choice(X_test.shape[0], sample_size, replace=False)\n",
    "# X = X[indices]\n",
    "# Y = Y[indices]\n",
    "# X_test = X_test[indices]\n",
    "# Y_test = Y_test[indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train number:  35700\n",
      "X_test number:  6300\n"
     ]
    }
   ],
   "source": [
    "# Then lets create x_train, y_train, x_test, y_test arrays\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15, random_state=42)\n",
    "\n",
    "number_of_train = X_train.shape[0]\n",
    "number_of_test = X_test.shape[0]\n",
    "print(\"X_train number: \" , number_of_train)\n",
    "print(\"X_test number: \" , number_of_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 为方便后续矩阵乘法的计算，对样本矩阵进行转置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train:  (35700, 784)\n",
      "x test:  (6300, 784)\n",
      "y train:  (35700,)\n",
      "y test:  (6300,)\n"
     ]
    }
   ],
   "source": [
    "y_train = Y_train.T\n",
    "y_test = Y_test.T\n",
    "print(\"x train: \",X_train.shape)\n",
    "print(\"x test: \",X_test.shape)\n",
    "print(\"y train: \",y_train.shape)\n",
    "print(\"y test: \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- <a id=\"10\"></a> <br>\n",
    "# 深度神经网络(DNN)\n",
    "* 2-layer 感知机: \n",
    "    * 神经网络结构： 包括输入层、一个或多个隐藏层以及输出层。\n",
    "    * 激活函数： 激活函数提供了非线性变换，使模型具备拟合复杂数据的能力。tanh激活函数比sigmoid更适合用于隐藏单元，因为它的输出均值更接近于零，从而更好地中心化数据以供下一层使用。\n",
    "\n",
    "<a href=\"http://ibb.co/eF315x\"><img src=\"http://preview.ibb.co/dajVyH/9.jpg\" alt=\"9\" border=\"0\"></a>\n",
    "\n",
    "   \n",
    "    \n",
    "     -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit called with sample_weight: [2.80112045e-05 2.80112045e-05 2.80112045e-05 ... 2.80112045e-05\n",
      " 2.80112045e-05 2.80112045e-05]\n",
      "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "Epoch 1/2, Accuracy: 0.99207283\n",
      "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "Epoch 2/2, Accuracy: 0.99084034\n",
      "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "Fit called with sample_weight: [2.82701495e-06 2.82701495e-06 2.82701495e-06 ... 2.82701495e-06\n",
      " 2.82701495e-06 2.82701495e-06]\n",
      "\u001b[1m1002/1002\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "Epoch 1/2, Accuracy: 1.00000000\n",
      "\u001b[1m1002/1002\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "Epoch 2/2, Accuracy: 1.00000000\n",
      "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "Fit called with sample_weight: [2.97611962e-07 5.07843359e-05 5.07843359e-05 ... 5.07843359e-05\n",
      " 5.07843359e-05 2.97611962e-07]\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "Epoch 1/2, Accuracy: 0.98780488\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "Epoch 2/2, Accuracy: 0.98318407\n",
      "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "Fit called with sample_weight: [3.02963841e-08 5.16975775e-06 5.16975775e-06 ... 5.16975775e-06\n",
      " 5.16975775e-06 3.02963841e-08]\n",
      "\u001b[1m1001/1001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "Epoch 1/2, Accuracy: 0.99756364\n",
      "\u001b[1m1001/1001\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "Epoch 2/2, Accuracy: 0.99481493\n",
      "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "Fit called with sample_weight: [6.79898368e-07 5.38574861e-07 1.16017471e-04 ... 1.16017471e-04\n",
      " 5.38574861e-07 3.15621576e-09]\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step\n",
      "Epoch 1/2, Accuracy: 0.98649915\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step\n",
      "Epoch 2/2, Accuracy: 0.98720201\n",
      "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step\n",
      "Fit called with sample_weight: [6.89523237e-08 5.46199107e-08 1.17659853e-05 ... 1.17659853e-05\n",
      " 5.46199107e-08 3.20089620e-10]\n",
      "\u001b[1m1010/1010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step\n",
      "Epoch 1/2, Accuracy: 0.99752452\n",
      "\u001b[1m1010/1010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step\n",
      "Epoch 2/2, Accuracy: 0.99557508\n",
      "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step\n",
      "Fit called with sample_weight: [7.37213901e-09 7.59895094e-07 1.25797761e-06 ... 1.63693320e-04\n",
      " 5.83976801e-09 3.42228521e-11]\n",
      "\u001b[1m970/970\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step\n",
      "Epoch 1/2, Accuracy: 0.99420066\n",
      "\u001b[1m970/970\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step\n",
      "Epoch 2/2, Accuracy: 0.99758361\n",
      "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step\n",
      "Fit called with sample_weight: [7.43645717e-10 7.66524792e-08 1.26895282e-07 ... 1.65121461e-05\n",
      " 5.89071702e-10 3.45214291e-12]\n",
      "\u001b[1m1003/1003\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step\n",
      "Epoch 1/2, Accuracy: 0.99663394\n",
      "\u001b[1m1003/1003\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step\n",
      "Epoch 2/2, Accuracy: 0.99622877\n",
      "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step\n",
      "Fit called with sample_weight: [7.98391082e-11 8.22954459e-09 1.36237000e-08 ... 2.16727664e-04\n",
      " 6.32437709e-11 3.70628116e-13]\n",
      "\u001b[1m1002/1002\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step\n",
      "Epoch 1/2, Accuracy: 0.98596513\n",
      "\u001b[1m1002/1002\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step\n",
      "Epoch 2/2, Accuracy: 0.99042510\n",
      "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step\n",
      "Fit called with sample_weight: [8.08398941e-12 8.33270220e-10 1.37944735e-09 ... 2.19444353e-05\n",
      " 4.59774462e-09 3.75273952e-14]\n",
      "\u001b[1m1002/1002\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step\n",
      "Epoch 1/2, Accuracy: 0.98923456\n",
      "\u001b[1m1002/1002\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step\n",
      "Epoch 2/2, Accuracy: 0.99890785\n",
      "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step\n",
      "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step\n",
      "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step\n",
      "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step\n",
      "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step\n",
      "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step\n",
      "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step\n",
      "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step\n",
      "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step\n",
      "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step\n",
      "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Train Accuracy: 100.00000000%\n",
      "Test Accuracy: 98.85714286%\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "Core_Size = 3\n",
    "\n",
    "class CNNClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, input_shape=(28, 28, 1), num_classes=10, epochs=3, batch_size=32):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.model = self._build_model()\n",
    "        self.n_classes_ = num_classes\n",
    "\n",
    "    def _build_model(self):\n",
    "        model = Sequential([\n",
    "            Conv2D(32, (Core_Size, Core_Size), activation='relu', input_shape=self.input_shape, padding='same'),\n",
    "            MaxPooling2D(pool_size=(2, 2)),\n",
    "            Conv2D(64, (Core_Size, Core_Size), activation='relu', padding='same'),\n",
    "            MaxPooling2D(pool_size=(2, 2)),\n",
    "            Conv2D(128, (Core_Size, Core_Size), activation='relu', padding='same'),\n",
    "            MaxPooling2D(pool_size=(2, 2)),\n",
    "            Flatten(),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dense(self.num_classes, activation='softmax')\n",
    "        ])\n",
    "        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "    \n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        # 设置类标签数量\n",
    "        self.classes_ = np.unique(y)\n",
    "        self.n_classes_ = len(self.classes_)\n",
    "        print(f\"Fit called with sample_weight: {sample_weight}\")\n",
    "        \n",
    "        if sample_weight is not None:\n",
    "            if len(sample_weight) != len(X):\n",
    "                raise ValueError(\"sample_weight length must be equal to number of samples\")\n",
    "            # 通过复制样本实现权重\n",
    "            sample_weight = sample_weight / np.sum(sample_weight)  # 归一化权重\n",
    "            sample_weight = (sample_weight * len(sample_weight)).astype(int)  # 扩展权重到整数倍\n",
    "            X_new = np.repeat(X, sample_weight, axis=0)\n",
    "            y_new = np.repeat(y, sample_weight, axis=0)\n",
    "        else:\n",
    "            X_new, y_new = X, y\n",
    "        \n",
    "        self.model.fit(X_new, y_new, epochs=self.epochs, batch_size=self.batch_size, verbose=0)\n",
    "        # 在每个弱分类器训练完之后打印其准确率\n",
    "        for epoch in range(self.epochs):\n",
    "            self.model.fit(X_new, y_new, epochs=1, batch_size=self.batch_size, verbose=0)\n",
    "            y_pred = self.model.predict(X_new)\n",
    "            accuracy = accuracy_score(y_new, np.argmax(y_pred, axis=1))\n",
    "            print(f\"Epoch {epoch + 1}/{self.epochs}, Accuracy: {accuracy:.8f}\")\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.model.predict(X), axis=1)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "\n",
    "# 确保数据形状\n",
    "X_train_reshaped = X_train.reshape((X_train.shape[0], 28, 28, 1))\n",
    "X_test_reshaped = X_test.reshape((X_test.shape[0], 28, 28, 1))\n",
    "\n",
    "# 确保标签为一维整数数组\n",
    "y_train_int = np.argmax(y_train, axis=1) if len(y_train.shape) > 1 else y_train\n",
    "y_test_int = np.argmax(y_test, axis=1) if len(y_test.shape) > 1 else y_test\n",
    "\n",
    "# 初始化CNN弱学习器\n",
    "cnn_weak_learner = CNNClassifier(epochs= 2)  # 使用较少的epoch数作为弱学习器\n",
    "\n",
    "# 初始化AdaBoost分类器，使用自定义的CNN弱学习器\n",
    "ada = AdaBoostClassifier(estimator=cnn_weak_learner, n_estimators=10, learning_rate=1.0, algorithm='SAMME')\n",
    "\n",
    "# 训练模型\n",
    "try:\n",
    "    ada.fit(X_train_reshaped, y_train_int)\n",
    "except TypeError as e:\n",
    "    print(f\"Error during model training: {e}\")\n",
    "\n",
    "# 进行预测\n",
    "y_pred_train = ada.predict(X_train_reshaped)\n",
    "y_pred_test = ada.predict(X_test_reshaped)\n",
    "\n",
    "# 计算准确率\n",
    "train_accuracy = accuracy_score(y_train_int, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test_int, y_pred_test)\n",
    "\n",
    "print(\"Train Accuracy: {:.8f}%\".format(train_accuracy * 100))\n",
    "print(\"Test Accuracy: {:.8f}%\".format(test_accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分割后的AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit called with sample_weight: None\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "Weak learner 1 accuracy: 0.98\n",
      "Fit called with sample_weight: None\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "Weak learner 2 accuracy: 0.98\n",
      "Fit called with sample_weight: None\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "Weak learner 3 accuracy: 0.97\n",
      "Fit called with sample_weight: None\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "Weak learner 4 accuracy: 0.93\n",
      "Fit called with sample_weight: None\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "Weak learner 5 accuracy: 0.98\n",
      "Fit called with sample_weight: None\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "Weak learner 6 accuracy: 0.98\n",
      "Fit called with sample_weight: None\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "Weak learner 7 accuracy: 0.98\n",
      "Fit called with sample_weight: None\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "Weak learner 8 accuracy: 0.98\n",
      "Fit called with sample_weight: None\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "Weak learner 9 accuracy: 0.98\n",
      "Fit called with sample_weight: None\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "Weak learner 10 accuracy: 0.98\n",
      "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step\n",
      "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step\n",
      "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step\n",
      "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step\n",
      "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step\n",
      "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step\n",
      "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step\n",
      "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step\n",
      "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step\n",
      "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step\n",
      "Train Accuracy: 89.18%\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "Test Accuracy: 88.62%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class CNNClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, input_shape=(28, 28, 1), num_classes=10, epochs=3, batch_size=32):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.model = self._build_model()\n",
    "        self.n_classes_ = num_classes\n",
    "    \n",
    "    def _build_model(self):\n",
    "        model = Sequential([\n",
    "            Conv2D(32, (5, 5), activation='relu', input_shape=self.input_shape, padding='same'),\n",
    "            MaxPooling2D(pool_size=(2, 2)),\n",
    "            Conv2D(64, (5, 5), activation='relu', padding='same'),\n",
    "            MaxPooling2D(pool_size=(2, 2)),\n",
    "            Conv2D(128, (5, 5), activation='relu', padding='same'),\n",
    "            MaxPooling2D(pool_size=(2, 2)),\n",
    "            Flatten(),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dense(self.num_classes, activation='softmax')\n",
    "        ])\n",
    "        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "    \n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        # 设置类标签数量\n",
    "        self.classes_ = np.unique(y)\n",
    "        self.n_classes_ = len(self.classes_)\n",
    "        print(f\"Fit called with sample_weight: {sample_weight}\")\n",
    "        \n",
    "        if sample_weight is not None:\n",
    "            if len(sample_weight) != len(X):\n",
    "                raise ValueError(\"sample_weight length must be equal to number of samples\")\n",
    "            # 通过复制样本实现权重\n",
    "            sample_weight = sample_weight / np.sum(sample_weight)  # 归一化权重\n",
    "            sample_weight = (sample_weight * len(sample_weight)).astype(int)  # 扩展权重到整数倍\n",
    "            X_new = np.repeat(X, sample_weight, axis=0)\n",
    "            y_new = np.repeat(y, sample_weight, axis=0)\n",
    "        else:\n",
    "            X_new, y_new = X, y\n",
    "        \n",
    "        self.model.fit(X_new, y_new, epochs=self.epochs, batch_size=self.batch_size, verbose=0)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.model.predict(X), axis=1)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "# 确保数据形状\n",
    "X_train_reshaped = X_train.reshape((X_train.shape[0], 28, 28, 1))\n",
    "X_test_reshaped = X_test.reshape((X_test.shape[0], 28, 28, 1))\n",
    "\n",
    "# 确保标签为一维整数数组\n",
    "y_train_int = np.argmax(y_train, axis=1) if len(y_train.shape) > 1 else y_train\n",
    "y_test_int = np.argmax(y_test, axis=1) if len(y_test.shape) > 1 else y_test\n",
    "\n",
    "# 分割数据集\n",
    "def split_data(X, y, n_splits=10):\n",
    "    X_splits = np.array_split(X, n_splits)\n",
    "    y_splits = np.array_split(y, n_splits)\n",
    "    return X_splits, y_splits\n",
    "\n",
    "X_splits, y_splits = split_data(X_train_reshaped, y_train_int, n_splits=10)\n",
    "\n",
    "# 初始化并训练AdaBoost分类器，使用自定义的CNN弱学习器\n",
    "cnn_weak_learner = CNNClassifier(epochs=1)  # 使用较少的epoch数作为弱学习器\n",
    "\n",
    "# 自己管理弱学习器的训练过程\n",
    "weak_learners = []\n",
    "for i in range(10):\n",
    "    learner = CNNClassifier(epochs=2)\n",
    "    X_sub, y_sub = X_splits[i], y_splits[i]  # 使用第i个子集\n",
    "    learner.fit(X_sub, y_sub)\n",
    "    weak_learners.append(learner)\n",
    "    accuracy = accuracy_score(y_sub, learner.predict(X_sub))\n",
    "    print(f\"Weak learner {i+1} accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# 集成结果\n",
    "y_pred_train = np.zeros_like(y_train_int)\n",
    "for learner in weak_learners:\n",
    "    y_pred_train += learner.predict(X_train_reshaped)\n",
    "\n",
    "y_pred_train = np.round(y_pred_train / len(weak_learners)).astype(int)\n",
    "train_accuracy = accuracy_score(y_train_int, y_pred_train)\n",
    "print(\"Train Accuracy: {:.2f}%\".format(train_accuracy * 100))\n",
    "\n",
    "y_pred_test = np.zeros_like(y_test_int)\n",
    "for learner in weak_learners:\n",
    "    y_pred_test += learner.predict(X_test_reshaped)\n",
    "\n",
    "y_pred_test = np.round(y_pred_test / len(weak_learners)).astype(int)\n",
    "test_accuracy = accuracy_score(y_test_int, y_pred_test)\n",
    "print(\"Test Accuracy: {:.2f}%\".format(test_accuracy * 100))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
